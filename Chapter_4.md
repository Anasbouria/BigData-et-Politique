# Chapter 3: Modèles prédictifs et politique
## Introduction : 

Big Data fait référence à de grandes quantités de données diverses générées et collectées par les organisations et les individus. Ces données peuvent inclure tout, des publications sur les réseaux sociaux et les transactions en ligne aux images satellites et aux données de capteurs. Des modèles prédictifs peuvent être développés à l'aide de données massives pour aider les décisions de campagne. Cependant, l'utilisation de Big Data en politique soulève également des préoccupations éthiques et de confidentialité importantes, telles que la collecte et l'utilisation de données personnelles sans consentement, la publicité politique ciblée, la discrimination et la manipulation de l'opinion publique, le manque de transparence et le biais dans les données et les modèles. Il est crucial pour les campagnes politiques, les organisations et les individus de comprendre les implications de Big Data et de travailler pour minimiser les biais dans leurs données et modèles tout en étant transparents sur leurs pratiques de collecte et d'utilisation de données.

## Manipulation de l'opinion publique et influence sur les élections :

La manipulation de l'opinion publique et de l'influence sur les élections font référence aux préoccupations selon lesquelles les données peuvent être utilisées pour cibler des groupes de personnes spécifiques avec certains messages ou publicités, ce qui pourrait potentiellement être utilisé pour manipuler l'opinion publique ou influencer le résultat des élections. Cela peut être fait en utilisant des données pour créer des campagnes publicitaires hautement spécifiques et ciblées, ou en utilisant des données pour identifier et influencer les groupes démographiques clés qui sont susceptibles de faire basculer une élection.

Un exemple de ceci est l'utilisation de données lors de l'élection présidentielle américaine de 2016 par Cambridge Analytica, une entreprise de conseil politique, qui a utilisé des données obtenues sur Facebook pour créer des campagnes publicitaires ciblées destinées à orienter l'opinion publique en faveur du candidat Donald Trump. L'entreprise a récolté des données personnelles de plus de 50 millions de profils Facebook sans le consentement des utilisateurs et a utilisé ces informations pour créer des profils psychologiques détaillés des individus. Cette information a ensuite été utilisée pour créer des campagnes publicitaires ciblées visant à influencer les opinions et les comportements de groupes spécifiques de personnes[^1].

Un autre exemple est l'utilisation de données par la campagne Leave.eu lors du référendum sur le Brexit au Royaume-Uni, qui a utilisé des données provenant de diverses sources pour créer des campagnes publicitaires ciblées destinées à influencer les opinions et les comportements de groupes spécifiques de personnes.

Ces exemples montrent comment les données peuvent être utilisées pour manipuler l'opinion publique et influencer les élections, soulevant des inquiétudes sur le potentiel d'utilisation des données pour miner l'intégrité des processus démocratiques.

## Discrimination :

Les données peuvent être utilisées pour discriminer certains groupes de personnes, comme en leur refusant l'accès à certains services ou opportunités. Cela peut se produire lorsque les données sont utilisées pour créer des algorithmes ou des modèles qui sont intrinsèquement biaisés contre certains groupes de personnes, ou lorsque les données sont utilisées pour prendre des décisions qui affectent de manière disproportionnée certains groupes de personnes.

Par exemple, on trouve l'utilisation de données dans le système de justice pénale, où les algorithmes et les modèles utilisés pour prédire la probabilité de récidive ont été reconnus comme étant biaisés contre certains groupes de personnes, comme les "accusés noirs". C'est parce que ces algorithmes sont souvent formés à partir de données historiques qui reflètent les biais existants dans le système de justice pénale, ce qui peut perpétuer ces biais dans les prédictions générées par les algorithmes.

On trouve également l'utilisation de données par les employeurs dans le processus de recrutement, où les algorithmes et les modèles utilisés pour prédire les performances professionnelles ont été reconnus comme étant biaisés contre certains groupes de personnes, comme les femmes et les minorités. C'est parce que ces algorithmes sont souvent formés à partir de données historiques qui reflètent les biais existants dans le processus de recrutement, ce qui peut également perpétuer ces biais dans les prédictions générées par les algorithmes.

Ces exemples montrent comment les données peuvent être utilisées pour discriminer certains groupes de personnes, soulevant des préoccupations quant au potentiel de l'utilisation des données pour perpétuer les biais et les inégalités existants dans la société.

## Les atteintes à la vie privée - Privacy breaches :

Lors des atteintes à la vie privée les données peuvent être collectées et utilisées sans que les individus en soient informés ou y aient consenti, ainsi qu'au risque que les données soient piratées ou divulguées, exposant ainsi des informations sensibles. Il s'agit d'une préoccupation majeure car les données personnelles peuvent révéler des informations sensibles sur les individus et peuvent être utilisées à des fins malveillantes.

Un exemple de cela est la violation de données chez Equifax, une agence de notation de crédit, en 2017, où des pirates ont eu accès à des informations personnelles sensibles de 147 millions de personnes, notamment des numéros de sécurité sociale, des dates de naissance, des adresses et des numéros de permis de conduire. Ces données peuvent être utilisées pour le vol d'identité et d'autres fins malveillantes. 

Cet exemple montre les conséquences graves des violations de données pour la vie privée et la sécurité des individus et comment ces violations peuvent être utilisées à des fins malveillantes. Il souligne également la nécessité de mesures de protection de données robustes pour s'assurer que les données personnelles sont collectées, stockées et utilisées de manière responsable.

## Manque de transparence

Lors du manque de transparence, la nature propriétaire des données et le manque de contrôle sur les données collectées et utilisées par des tiers ne permettent pas aux individus de comprendre comment leurs données sont utilisées. Ce manque de transparence peut rendre difficile pour les individus de prendre des décisions éclairées sur la façon dont leurs données sont partagées, et il peut être difficile de rendre les organisations responsables de l'utilisation de leurs données. En d'autres termes, il est important pour les individus de savoir comment leurs données sont collectées, utilisées, stockées et protégées, et quelles sont les conséquences de leur partage. Cela permet aux individus de prendre des décisions informées sur la façon dont ils souhaitent partager leurs données et de s'assurer que les organisations respectent les normes de protection de la vie privée.

## Conclusion : 

Il existe plusieurs mesures qui peuvent être prises pour aborder les préoccupations éthiques liées à l'utilisation de données massives :

- Transparence : les organisations et les gouvernements devraient être transparents sur la façon dont ils collectent, stockent et utilisent les données, et les individus devraient être informés de quelles données sont collectées à leur sujet, comment elles sont utilisées et avec qui elles sont partagées.

- Équité et biais : les algorithmes et les modèles devraient être régulièrement audités et évalués pour l'équité, et tout biais identifié devrait être traité. De plus, les données devraient être collectées et utilisées de manière à respecter les droits des individus et à ne pas perpétuer les biais ou les inégalités existants dans la société.

- Vie privée : des mesures de protection de données robustes devraient être mises en place pour s'assurer que les données personnelles sont collectées, stockées et utilisées de manière responsable et que la vie privée des individus est protégée.

- Gouvernance : les organisations devraient établir des politiques et des procédures de gouvernance de données efficaces et se conformer aux exigences légales et réglementaires liées à l'utilisation des données.

- Éducation et sensibilisation : Il devrait y avoir plus de programmes d'éducation et de sensibilisation sur les implications éthiques et de confidentialité des données massives et de l'apprentissage automatique, non seulement pour le grand public, mais également pour les développeurs et les décideurs travaillant avec des données.

- Responsabilité : Les organisations et les individus doivent être tenus responsables de la manière dont ils collectent, stockent et utilisent les données, et de s'assurer que les données sont utilisées de manière à respecter les droits des individus et à ne pas perpétuer les biais ou les inégalités existants dans la société.

- Collaboration : Il devrait y avoir plus de collaboration entre le gouvernement, l'industrie et la société civile pour aborder les préoccupations éthiques et établir des bonnes pratiques pour l'utilisation des données.

Il est important de souligner que l'abordage des préoccupations éthiques est un processus en cours, car les technologies et les pratiques de données évoluent constamment, et de nouveaux défis peuvent survenir. 


## Références : 

[^1]: [Facebook–Cambridge Analytica data scandal](https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal#:~:text=In%20the%202010s%2C%20personal%20data,be%20used%20for%20political%20advertising.)